{
  "id": "snapshot_1758895433031_9srtm1pll",
  "approvalId": "approval_1758895433020_qnhhqy87b",
  "approvalTitle": "Approve tasks for Houdini Ollama integration",
  "version": 1,
  "timestamp": "2025-09-26T14:03:53.031Z",
  "trigger": "initial",
  "status": "pending",
  "content": "# Tasks Document\r\n\r\n- [ ] 1. Stabilize WebChannel bootstrap in `houdini_plugin/main.py`\r\n  - File: `houdini_plugin/main.py`\r\n  - Ensure WebChannel initialization emits ping/ready signals, retries gracefully, and avoids crashes.\r\n  - _Leverage: existing `create_window` setup, `HostBridge`, `AppAPI`_\r\n  - _Requirements: 1.1, 1.2, 3.1_\r\n  - _Prompt: Role: PySide6 Developer focusing on Qt WebEngine integration | Task: Implement reliable WebChannel bootstrap with ping handshake and retry logic per requirements 1.1, 1.2, and 3.1 in `houdini_plugin/main.py`, ensuring Houdini does not crash on failure | Restrictions: Do not remove existing API stubs, avoid blocking loops, maintain compatibility with current logging hooks | _Leverage: use `QWebEngineScript`, existing `HostBridge` signals, logging helpers | Requirements: 1.1, 1.2, 3.1 | Success: WebChannel ready is logged, ping returns \"pong\", failures log descriptive warnings without crashing._\r\n\r\n- [ ] 2. Implement Python-side Ollama proxy endpoints\r\n  - File: `houdini_plugin/main.py`\r\n  - Extend `NetworkAPI` with `openaiFetch` wrapper, structured logging, and resilient error handling for `/api/tags` and `/v1/models`.\r\n  - _Leverage: current `ollamaListModels`, `fetchProxy` implementation_\r\n  - _Requirements: 2.1, 2.2, 3.2_\r\n  - _Prompt: Role: Python Backend Engineer specializing in REST proxies | Task: Implement `NetworkAPI.openaiFetch` and enhance existing Ollama slots per requirements 2.1, 2.2, 3.2, returning structured JSON and logging requests/responses | Restrictions: Only allow localhost targets, sanitize input, preserve backwards compatibility with current callers | _Leverage: urllib, logging helper, existing slot signatures | Requirements: 2.1, 2.2, 3.2 | Success: `/api/tags` and `/v1/models` calls succeed via proxy, errors return structured payloads, logs capture URL/method/status._\r\n\r\n- [ ] 3. Add diagnostics helper and structured logging utilities\r\n  - File: `houdini_plugin/main.py` (new helper section)\r\n  - Create reusable functions to log WebChannel/object states and proxy outcomes; ensure all paths use them.\r\n  - _Leverage: existing print-based logs_\r\n  - _Requirements: 3.1, 3.2, 3.3_\r\n  - _Prompt: Role: Observability Engineer with Python expertise | Task: Build structured logging helpers per requirements 3.1â€“3.3, ensuring all WebChannel and network operations use consistent logging format | Restrictions: Keep helper pure (no side effects beyond logging), do not spam excessive logs; maintain Houdini stability | _Leverage: Python logging/print wrappers | Requirements: 3.1, 3.2, 3.3 | Success: Logs include object exposure, retry attempts, URL/method/status, and error stack traces._\r\n\r\n- [ ] 4. Update frontend Ollama adapter to use Qt slots\r\n  - File: `web/src/renderer/src/aiCore/legacy/clients/openai/OpenAIBaseClient.ts`\r\n  - Refactor Ollama branch to call new `qt.network` slots with fallback handling and improved warnings.\r\n  - _Leverage: existing `OpenAIBaseClient` Ollama branch, logger service_\r\n  - _Requirements: 2.1, 2.3_\r\n  - _Prompt: Role: TypeScript Developer with Cherry Studio familiarity | Task: Refactor the Ollama branch to prefer Qt slot calls, handle fallback to window.api, and surface informative logs per requirements 2.1 and 2.3 | Restrictions: Do not break other providers, maintain typings, avoid introducing new dependencies | _Leverage: loggerService, window.qt typings | Requirements: 2.1, 2.3 | Success: Frontend displays model list when proxy works, warns gracefully when offline, no `Connection error` regressions._\r\n\r\n- [ ] 5. Document and verify diagnostics workflow\r\n  - File: `docs/houdini-ollama-troubleshooting.md` (new)\r\n  - Write troubleshooting guide outlining logs, ping checks, and retry steps; verify by running manual test plan.\r\n  - _Leverage: new logging outputs, existing README patterns_\r\n  - _Requirements: 3.3, Reliability, Usability_\r\n  - _Prompt: Role: Technical Writer with QA background | Task: Document diagnostics workflow and execute manual verification per requirements 3.3 and non-functional goals, creating `docs/houdini-ollama-troubleshooting.md` | Restrictions: Keep documentation concise (<2 pages), include command snippets, ensure instructions reflect actual implementation | _Leverage: current logs, manual test results | Requirements: 3.3, Reliability, Usability | Success: Document explains how to confirm WebChannel readiness, interpret logs, and recover from failures; manual test checklist completed._\r\n",
  "fileStats": {
    "size": 4482,
    "lines": 37,
    "lastModified": "2025-09-26T14:03:45.195Z"
  },
  "comments": []
}
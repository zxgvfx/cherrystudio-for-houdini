<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cherry Studio for Houdini</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .chat-container {
            width: 90%;
            max-width: 1200px;
            height: 90vh;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.1);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }
        
        .chat-header {
            background: linear-gradient(135deg, #ff6b6b, #ee5a52);
            color: white;
            padding: 20px;
            text-align: center;
            position: relative;
        }
        
        .chat-header h1 {
            font-size: 24px;
            font-weight: 600;
        }
        
        .chat-header .subtitle {
            font-size: 14px;
            opacity: 0.9;
            margin-top: 5px;
        }
        
        .model-selector {
            position: absolute;
            top: 20px;
            left: 20px;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .model-select {
            background: rgba(255, 255, 255, 0.2);
            border: 1px solid rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            color: white;
            padding: 6px 12px;
            font-size: 12px;
            cursor: pointer;
            backdrop-filter: blur(10px);
        }
        
        .model-select:hover {
            background: rgba(255, 255, 255, 0.3);
        }
        
        .model-select option {
            background: #333;
            color: white;
        }
        
        .config-button {
            position: absolute;
            top: 20px;
            right: 60px;
            background: rgba(255, 255, 255, 0.2);
            border: 1px solid rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            color: white;
            padding: 6px 12px;
            font-size: 12px;
            cursor: pointer;
            backdrop-filter: blur(10px);
            text-decoration: none;
            display: inline-block;
        }
        
        .config-button:hover {
            background: rgba(255, 255, 255, 0.3);
        }
        
        .status-indicator {
            position: absolute;
            top: 20px;
            right: 20px;
            width: 12px;
            height: 12px;
            background: #4ade80;
            border-radius: 50%;
            animation: pulse 2s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        
        .chat-messages {
            flex: 1;
            padding: 20px;
            overflow-y: auto;
            background: #f8fafc;
        }
        
        .message {
            margin-bottom: 20px;
            display: flex;
            align-items: flex-start;
            gap: 12px;
        }
        
        .message.user {
            flex-direction: row-reverse;
        }
        
        .message-avatar {
            width: 40px;
            height: 40px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            color: white;
            flex-shrink: 0;
        }
        
        .message.bot .message-avatar {
            background: linear-gradient(135deg, #667eea, #764ba2);
        }
        
        .message.user .message-avatar {
            background: linear-gradient(135deg, #ff6b6b, #ee5a52);
        }
        
        .message-content {
            max-width: 70%;
            padding: 15px 20px;
            border-radius: 20px;
            position: relative;
            word-wrap: break-word;
        }
        
        .message.bot .message-content {
            background: white;
            border: 1px solid #e2e8f0;
            border-bottom-left-radius: 5px;
        }
        
        .message.user .message-content {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            border-bottom-right-radius: 5px;
        }
        
        .message-time {
            font-size: 11px;
            opacity: 0.7;
            margin-top: 5px;
        }
        
        .chat-input-container {
            padding: 20px;
            background: white;
            border-top: 1px solid #e2e8f0;
        }
        
        .chat-input-wrapper {
            display: flex;
            gap: 12px;
            align-items: flex-end;
        }
        
        .chat-input {
            flex: 1;
            min-height: 50px;
            max-height: 120px;
            padding: 15px 20px;
            border: 2px solid #e2e8f0;
            border-radius: 25px;
            font-size: 16px;
            resize: none;
            outline: none;
            transition: border-color 0.3s ease;
        }
        
        .chat-input:focus {
            border-color: #667eea;
        }
        
        .send-button {
            width: 50px;
            height: 50px;
            background: linear-gradient(135deg, #667eea, #764ba2);
            border: none;
            border-radius: 50%;
            color: white;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: transform 0.2s ease;
        }
        
        .send-button:hover {
            transform: scale(1.05);
        }
        
        .send-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }
        
        .welcome-message {
            text-align: center;
            color: #64748b;
            margin: 40px 0;
        }
        
        .welcome-message h2 {
            color: #334155;
            margin-bottom: 10px;
        }
        
        .feature-list {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        
        .feature-item {
            padding: 15px;
            background: white;
            border-radius: 10px;
            border: 1px solid #e2e8f0;
            text-align: center;
        }
        
        .feature-item .icon {
            font-size: 24px;
            margin-bottom: 8px;
        }
        
        .typing-indicator {
            display: none;
            padding: 15px 20px;
            background: white;
            border: 1px solid #e2e8f0;
            border-radius: 20px;
            border-bottom-left-radius: 5px;
            max-width: 70%;
        }
        
        .typing-dots {
            display: flex;
            gap: 4px;
        }
        
        .typing-dots span {
            width: 8px;
            height: 8px;
            background: #667eea;
            border-radius: 50%;
            animation: typing 1.4s infinite ease-in-out;
        }
        
        .typing-dots span:nth-child(1) { animation-delay: -0.32s; }
        .typing-dots span:nth-child(2) { animation-delay: -0.16s; }
        
        @keyframes typing {
            0%, 80%, 100% { transform: scale(0.8); opacity: 0.5; }
            40% { transform: scale(1); opacity: 1; }
        }
    </style>
</head>
<body>
    <div class="chat-container">
        <div class="chat-header">
            <div class="model-selector">
                <span style="font-size: 12px; opacity: 0.9;">Ê®°Âûã:</span>
                <select class="model-select" id="model-select">
                    <option value="gpt-4">GPT-4</option>
                    <option value="gpt-3.5-turbo" selected>GPT-3.5 Turbo</option>
                    <option value="claude-3">Claude 3</option>
                    <option value="gemini-pro">Gemini Pro</option>
                    <option value="local-llm">Êú¨Âú∞Ê®°Âûã</option>
                </select>
            </div>
            <a href="config.html" class="config-button">‚öôÔ∏è ÈÖçÁΩÆ</a>
            <div class="status-indicator" id="status-indicator"></div>
            <h1>üçí Cherry Studio for Houdini</h1>
            <div class="subtitle">AI Assistant Integrated with Houdini</div>
        </div>
        
        <div class="chat-messages" id="chat-messages">
            <div class="welcome-message">
                <h2>Welcome to Cherry Studio!</h2>
                <p>Your AI assistant is ready to help you with Houdini workflows.</p>
                
                <div class="feature-list">
                    <div class="feature-item">
                        <div class="icon">üé®</div>
                        <div>Houdini Integration</div>
                    </div>
                    <div class="feature-item">
                        <div class="icon">ü§ñ</div>
                        <div>AI Chat Assistant</div>
                    </div>
                    <div class="feature-item">
                        <div class="icon">üìÅ</div>
                        <div>Drag & Drop Support</div>
                    </div>
                    <div class="feature-item">
                        <div class="icon">‚ö°</div>
                        <div>Real-time Processing</div>
                    </div>
                </div>
                
                <p>Start by typing a message below!</p>
            </div>
        </div>
        
        <div class="typing-indicator" id="typing-indicator">
            <div class="typing-dots">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="chat-input-container">
            <div class="chat-input-wrapper">
                <textarea 
                    class="chat-input" 
                    id="chat-input" 
                    placeholder="Type your message here... (Shift+Enter for new line)"
                    rows="1"
                ></textarea>
                <button class="send-button" id="send-button">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M2.01 21L23 12 2.01 3 2 10l15 2-15 2z"/>
                    </svg>
                </button>
            </div>
        </div>
    </div>

    <script>
        class CherryStudioChat {
            constructor() {
                this.chatMessages = document.getElementById('chat-messages');
                this.chatInput = document.getElementById('chat-input');
                this.sendButton = document.getElementById('send-button');
                this.typingIndicator = document.getElementById('typing-indicator');
                this.statusIndicator = document.getElementById('status-indicator');
                this.modelSelect = document.getElementById('model-select');
                
                this.currentModel = 'gpt-3.5-turbo';
                this.init();
            }
            
            init() {
                // Set up event listeners
                this.sendButton.addEventListener('click', () => this.sendMessage());
                this.chatInput.addEventListener('keydown', (e) => this.handleKeyDown(e));
                this.chatInput.addEventListener('input', () => this.adjustTextareaHeight());
                this.modelSelect.addEventListener('change', (e) => this.changeModel(e.target.value));
                
                // Load configuration
                this.loadConfiguration();
                
                // Test connection to Houdini bridge
                this.testHoudiniConnection();
                
                // Add welcome message
                this.addBotMessage(`Hello! I'm your Cherry Studio AI assistant (${this.currentModel}). I'm now integrated with Houdini and ready to help you with your 3D workflows. What would you like to know?`);
            }
            
            handleKeyDown(e) {
                if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    this.sendMessage();
                }
            }
            
            adjustTextareaHeight() {
                this.chatInput.style.height = 'auto';
                this.chatInput.style.height = Math.min(this.chatInput.scrollHeight, 120) + 'px';
            }
            
            changeModel(modelId) {
                this.currentModel = modelId;
                console.log(`Model changed to: ${modelId}`);
                
                // Add a system message about model change
                this.addBotMessage(`Ê®°ÂûãÂ∑≤ÂàáÊç¢Âà∞: **${this.getModelDisplayName(modelId)}**\n\nÁé∞Âú®ÊàëÂ∞Ü‰ΩøÁî®Êñ∞ÁöÑÊ®°ÂûãÊù•ÂõûÁ≠îÊÇ®ÁöÑÈóÆÈ¢ò„ÄÇ`);
            }
            
            getModelDisplayName(modelId) {
                const modelNames = {
                    'gpt-4': 'GPT-4',
                    'gpt-3.5-turbo': 'GPT-3.5 Turbo',
                    'claude-3': 'Claude 3',
                    'gemini-pro': 'Gemini Pro',
                    'local-llm': 'Êú¨Âú∞Ê®°Âûã'
                };
                return modelNames[modelId] || modelId;
            }
            
            loadConfiguration() {
                const saved = localStorage.getItem('cherry-studio-config');
                const skipConfig = localStorage.getItem('cherry-studio-skip-config');
                
                if (skipConfig === 'true') {
                    // Áî®Êà∑ÈÄâÊã©Ë∑≥ËøáÈÖçÁΩÆÔºå‰ΩøÁî®Ê®°ÊãüÂìçÂ∫î
                    this.config = null;
                    this.addBotMessage('‚ÑπÔ∏è ÊÇ®ÈÄâÊã©‰∫ÜË∑≥ËøáÈÖçÁΩÆÔºåÂ∞Ü‰ΩøÁî®Ê®°ÊãüÂìçÂ∫î„ÄÇÂ¶ÇÈúÄ‰ΩøÁî®ÁúüÂÆûÁöÑ AI Ê®°ÂûãÔºåËØ∑ÁÇπÂáªÂè≥‰∏äËßíÁöÑÈÖçÁΩÆÊåâÈíÆ„ÄÇ');
                    return;
                }
                
                if (saved) {
                    this.config = JSON.parse(saved);
                    console.log('Configuration loaded:', this.config);
                } else {
                    // No configuration found, redirect to config page
                    this.addBotMessage('‚ö†Ô∏è Êú™ÊâæÂà∞ AI Ê®°ÂûãÈÖçÁΩÆ„ÄÇËØ∑ÂÖàÈÖçÁΩÆÊÇ®ÁöÑ API ÂØÜÈí•„ÄÇ');
                    setTimeout(() => {
                        window.location.href = 'config.html';
                    }, 2000);
                }
            }
            
            async sendMessage() {
                const message = this.chatInput.value.trim();
                if (!message) return;
                
                // Add user message
                this.addUserMessage(message);
                
                // Clear input
                this.chatInput.value = '';
                this.adjustTextareaHeight();
                
                // Show typing indicator
                this.showTyping();
                
                // Disable send button
                this.sendButton.disabled = true;
                
                try {
                    // Simulate AI response (replace with actual AI integration)
                    const response = await this.getAIResponse(message);
                    this.hideTyping();
                    this.addBotMessage(response);
                } catch (error) {
                    this.hideTyping();
                    this.addBotMessage("Sorry, I encountered an error. Please try again.");
                    console.error('AI response error:', error);
                } finally {
                    this.sendButton.disabled = false;
                }
            }
            
            addUserMessage(message) {
                const messageDiv = document.createElement('div');
                messageDiv.className = 'message user';
                messageDiv.innerHTML = `
                    <div class="message-avatar">U</div>
                    <div class="message-content">
                        ${this.formatMessage(message)}
                        <div class="message-time">${this.getCurrentTime()}</div>
                    </div>
                `;
                this.chatMessages.appendChild(messageDiv);
                this.scrollToBottom();
            }
            
            addBotMessage(message) {
                const messageDiv = document.createElement('div');
                messageDiv.className = 'message bot';
                messageDiv.innerHTML = `
                    <div class="message-avatar">ü§ñ</div>
                    <div class="message-content">
                        ${this.formatMessage(message)}
                        <div class="message-time">${this.getCurrentTime()}</div>
                    </div>
                `;
                this.chatMessages.appendChild(messageDiv);
                this.scrollToBottom();
            }
            
            formatMessage(message) {
                // Simple markdown-like formatting
                return message
                    .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>')
                    .replace(/\*(.*?)\*/g, '<em>$1</em>')
                    .replace(/`(.*?)`/g, '<code>$1</code>')
                    .replace(/\n/g, '<br>');
            }
            
            getCurrentTime() {
                return new Date().toLocaleTimeString([], {hour: '2-digit', minute:'2-digit'});
            }
            
            showTyping() {
                this.typingIndicator.style.display = 'block';
                this.scrollToBottom();
            }
            
            hideTyping() {
                this.typingIndicator.style.display = 'none';
            }
            
            scrollToBottom() {
                setTimeout(() => {
                    this.chatMessages.scrollTop = this.chatMessages.scrollHeight;
                }, 100);
            }
            
            async getAIResponse(message) {
                if (!this.config) {
                    return "‚ùå ÈîôËØØÔºöÊú™ÊâæÂà∞ÈÖçÁΩÆ‰ø°ÊÅØ„ÄÇËØ∑ÈáçÊñ∞ÈÖçÁΩÆÊÇ®ÁöÑ AI Ê®°Âûã„ÄÇ";
                }
                
                try {
                    // Try to use real API calls based on the selected model
                    const response = await this.callRealAPI(message);
                    return response;
                } catch (error) {
                    console.error('API call failed:', error);
                    // Fallback to mock responses
                    const modelResponses = {
                        'gpt-4': this.getGPT4Response(message),
                        'gpt-3.5-turbo': this.getGPT35Response(message),
                        'claude-3': this.getClaude3Response(message),
                        'gemini-pro': this.getGeminiResponse(message),
                        'local-llm': this.getLocalLLMResponse(message)
                    };
                    
                    return modelResponses[this.currentModel] || modelResponses['gpt-3.5-turbo'];
                }
            }
            
            async callRealAPI(message) {
                const systemPrompt = this.config.general?.systemPrompt || 
                    "ÊÇ®ÊòØ‰∏Ä‰∏™‰∏ì‰∏öÁöÑ Houdini 3D Ëâ∫ÊúØÂÆ∂ÂíåÁ®ãÂ∫èÂëòÂä©Êâã„ÄÇËØ∑Áî®‰∏≠ÊñáÂõûÁ≠îÁî®Êà∑ÂÖ≥‰∫é Houdini Â∑•‰ΩúÊµÅÁ®ã„ÄÅËäÇÁÇπËÆæÁΩÆ„ÄÅËÑöÊú¨ÁºñÂÜôÂíå 3D Âà∂‰ΩúÁöÑÈóÆÈ¢ò„ÄÇ";
                
                switch (this.currentModel) {
                    case 'gpt-4':
                    case 'gpt-3.5-turbo':
                        return await this.callOpenAI(message, systemPrompt);
                    case 'claude-3':
                        return await this.callClaude(message, systemPrompt);
                    case 'gemini-pro':
                        return await this.callGemini(message, systemPrompt);
                    case 'local-llm':
                        return await this.callLocalLLM(message, systemPrompt);
                    default:
                        throw new Error('Unknown model');
                }
            }
            
            async callOpenAI(message, systemPrompt) {
                if (!this.config.openai?.key) {
                    throw new Error('OpenAI API ÂØÜÈí•Êú™ÈÖçÁΩÆ');
                }
                
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${this.config.openai.key}`
                    },
                    body: JSON.stringify({
                        model: this.currentModel === 'gpt-4' ? 'gpt-4' : 'gpt-3.5-turbo',
                        messages: [
                            { role: 'system', content: systemPrompt },
                            { role: 'user', content: message }
                        ],
                        temperature: this.config.general?.temperature || 0.7,
                        max_tokens: this.config.general?.maxTokens || 2048
                    })
                });
                
                if (!response.ok) {
                    throw new Error(`OpenAI API ÈîôËØØ: ${response.status}`);
                }
                
                const data = await response.json();
                return data.choices[0].message.content;
            }
            
            async callClaude(message, systemPrompt) {
                if (!this.config.claude?.key) {
                    throw new Error('Claude API ÂØÜÈí•Êú™ÈÖçÁΩÆ');
                }
                
                // Claude API Ë∞ÉÁî®ÂÆûÁé∞
                throw new Error('Claude API Ë∞ÉÁî®Â∞öÊú™ÂÆûÁé∞');
            }
            
            async callGemini(message, systemPrompt) {
                if (!this.config.gemini?.key) {
                    throw new Error('Gemini API ÂØÜÈí•Êú™ÈÖçÁΩÆ');
                }
                
                // Gemini API Ë∞ÉÁî®ÂÆûÁé∞
                throw new Error('Gemini API Ë∞ÉÁî®Â∞öÊú™ÂÆûÁé∞');
            }
            
            async callLocalLLM(message, systemPrompt) {
                // Â∞ùËØï Ollama
                if (this.config.local?.ollamaHost) {
                    try {
                        const response = await fetch(`${this.config.local.ollamaHost}/api/generate`, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                model: this.config.local.model || 'llama2',
                                prompt: `${systemPrompt}\n\nÁî®Êà∑: ${message}\nÂä©Êâã:`,
                                stream: false
                            })
                        });
                        
                        if (response.ok) {
                            const data = await response.json();
                            return data.response;
                        }
                    } catch (error) {
                        console.log('Ollama failed, trying LM Studio');
                    }
                }
                
                // Â∞ùËØï LM Studio
                if (this.config.local?.lmstudioHost) {
                    try {
                        const response = await fetch(`${this.config.local.lmstudioHost}/v1/chat/completions`, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                model: this.config.local.model || 'local-model',
                                messages: [
                                    { role: 'system', content: systemPrompt },
                                    { role: 'user', content: message }
                                ],
                                temperature: this.config.general?.temperature || 0.7,
                                max_tokens: this.config.general?.maxTokens || 2048
                            })
                        });
                        
                        if (response.ok) {
                            const data = await response.json();
                            return data.choices[0].message.content;
                        }
                    } catch (error) {
                        console.log('LM Studio failed');
                    }
                }
                
                throw new Error('Êú¨Âú∞Ê®°ÂûãÊúçÂä°‰∏çÂèØÁî®');
            }
            
            getGPT4Response(message) {
                const lowerMessage = message.toLowerCase();
                if (lowerMessage.includes('houdini') || lowerMessage.includes('3d')) {
                    return "‰Ωú‰∏∫ GPT-4ÔºåÊàëÂèØ‰ª•‰∏∫ÊÇ®Êèê‰æõÊ∑±ÂÖ•ÁöÑ Houdini ÊåáÂØºÔºö\n\n‚Ä¢ **È´òÁ∫ßËäÇÁÇπÁΩëÁªú** - Â§çÊùÇÁöÑÁ®ãÂ∫èÂåñÂ∑•‰ΩúÊµÅÁ®ãËÆæËÆ°\n‚Ä¢ **VEX ÁºñÁ®ã** - È´òÊïàÁöÑÁùÄËâ≤Âô®ÂíåÂá†‰Ωï‰ΩìÂ§ÑÁêÜ\n‚Ä¢ **Python ÈõÜÊàê** - Ëá™Âä®ÂåñËÑöÊú¨ÂíåÂ∑•ÂÖ∑ÂºÄÂèë\n‚Ä¢ **Ê∏≤Êüì‰ºòÂåñ** - Mantra Âíå Karma Ê∏≤ÊüìÂô®ËÆæÁΩÆ\n‚Ä¢ **Á≤íÂ≠êÁ≥ªÁªü** - È´òÁ∫ßÁâπÊïàÂíåÊ®°Êãü\n\nËØ∑ÂëäËØâÊàëÊÇ®ÂÖ∑‰ΩìÊÉ≥Ë¶Å‰∫ÜËß£Âì™‰∏™ÊñπÈù¢Ôºü";
                }
                return `[GPT-4] ÊÑüË∞¢ÊÇ®ÁöÑÊ∂àÊÅØÔºö"${message}"\n\n‰Ωú‰∏∫ÊúÄÂÖàËøõÁöÑËØ≠Ë®ÄÊ®°ÂûãÔºåÊàëÂèØ‰ª•‰∏∫ÊÇ®Êèê‰æõËØ¶ÁªÜÁöÑÊäÄÊúØÂàÜÊûêÂíåËß£ÂÜ≥ÊñπÊ°à„ÄÇËØ∑ÊèèËø∞ÊÇ®ÈÅáÂà∞ÁöÑÂÖ∑‰ΩìÈóÆÈ¢òÔºåÊàë‰ºöÁªôÂá∫ÂÖ®Èù¢ÁöÑÂõûÁ≠î„ÄÇ`;
            }
            
            getGPT35Response(message) {
                const lowerMessage = message.toLowerCase();
                if (lowerMessage.includes('houdini') || lowerMessage.includes('3d')) {
                    return "Hello! I'm GPT-3.5 Turbo, ready to help with Houdini:\n\n‚Ä¢ **Node workflows** - Setting up complex node networks\n‚Ä¢ **Procedural modeling** - Creating parametric 3D models\n‚Ä¢ **Animation** - Keyframe and procedural animation\n‚Ä¢ **Rendering** - Optimizing render settings\n‚Ä¢ **Scripting** - Python and VEX scripting\n\nWhat specific aspect would you like to explore?";
                }
                return `Thanks for your message: "${message}"\n\nI'm GPT-3.5 Turbo, your efficient AI assistant for Houdini workflows. How can I help you today?`;
            }
            
            getClaude3Response(message) {
                const lowerMessage = message.toLowerCase();
                if (lowerMessage.includes('houdini') || lowerMessage.includes('3d')) {
                    return "‰Ωú‰∏∫ Claude 3ÔºåÊàë‰∏ìÊ≥®‰∫éÂàõÊÑèÂíåÊäÄÊúØÂπ≥Ë°°ÁöÑËß£ÂÜ≥ÊñπÊ°àÔºö\n\n‚Ä¢ **ÂàõÊÑèÂ∑•‰ΩúÊµÅÁ®ã** - Ëâ∫ÊúØÂØºÂêëÁöÑÁ®ãÂ∫èÂåñÂª∫Ê®°\n‚Ä¢ **ÊäÄÊúØÂÆûÁé∞** - Á≤æÁ°ÆÁöÑËäÇÁÇπÈÖçÁΩÆÂíåÂèÇÊï∞Ë∞ÉËäÇ\n‚Ä¢ **‰ºòÂåñÂª∫ËÆÆ** - ÊÄßËÉΩÂíåË¥®ÈáèÁöÑÂπ≥Ë°°\n‚Ä¢ **ÊúÄ‰Ω≥ÂÆûË∑µ** - Ë°å‰∏öÊ†áÂáÜÁöÑ Houdini Â∑•‰ΩúÊµÅÁ®ã\n\nËØ∑ÂàÜ‰∫´ÊÇ®ÁöÑÂàõÊÑèÊÉ≥Ê≥ïÊàñÊäÄÊúØÊåëÊàòÔºÅ";
                }
                return `[Claude 3] ÊÑüË∞¢ÂàÜ‰∫´Ôºö"${message}"\n\nÊàëËá¥Âäõ‰∫éÊèê‰æõÊó¢ÊúâÂàõÊÑèÂèàÂÆûÁî®ÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇËØ∑ÂëäËØâÊàëÊÇ®ÁöÑÈ°πÁõÆÈúÄÊ±ÇÔºåÊàë‰ºöÁªìÂêàËâ∫ÊúØÊÄßÂíåÊäÄÊúØÊÄßÊù•Â∏ÆÂä©ÊÇ®„ÄÇ`;
            }
            
            getGeminiResponse(message) {
                const lowerMessage = message.toLowerCase();
                if (lowerMessage.includes('houdini') || lowerMessage.includes('3d')) {
                    return "‰Ωú‰∏∫ Gemini ProÔºåÊàëÊèê‰æõÂ§öÊ®°ÊÄÅÁöÑ Houdini ÊîØÊåÅÔºö\n\n‚Ä¢ **ËßÜËßâÁêÜËß£** - ÂàÜÊûêÊÇ®ÁöÑ 3D Âú∫ÊôØÂíåÊ®°Âûã\n‚Ä¢ **‰ª£Á†ÅÁîüÊàê** - Ëá™Âä®ÁîüÊàê Houdini ËÑöÊú¨ÂíåËäÇÁÇπÁΩëÁªú\n‚Ä¢ **Â§öËØ≠Ë®ÄÊîØÊåÅ** - ‰∏≠Ëã±ÊñáÊ∑∑ÂêàÁöÑÊäÄÊúØÊñáÊ°£\n‚Ä¢ **ÂÆûÊó∂Âçè‰Ωú** - ‰∏éÊÇ®ÁöÑÂàõÊÑèËøáÁ®ãÂêåÊ≠•\n\nËØ∑‰∏ä‰º†ÊÇ®ÁöÑÈ°πÁõÆÊñá‰ª∂ÊàñÊèèËø∞ÊÇ®ÁöÑËßÜËßâÈúÄÊ±ÇÔºÅ";
                }
                return `[Gemini Pro] Êî∂Âà∞ÊÇ®ÁöÑÊ∂àÊÅØÔºö"${message}"\n\n‰Ωú‰∏∫Â§öÊ®°ÊÄÅ AIÔºåÊàëÂèØ‰ª•Â§ÑÁêÜÊñáÊú¨„ÄÅÂõæÂÉèÂíå‰ª£Á†Å„ÄÇËØ∑ÂàÜ‰∫´ÊÇ®ÁöÑÈ°πÁõÆÊñá‰ª∂ÊàñÊèèËø∞ÔºåÊàë‰ºöÊèê‰æõÁªºÂêàÊÄßÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ`;
            }
            
            getLocalLLMResponse(message) {
                const lowerMessage = message.toLowerCase();
                if (lowerMessage.includes('houdini') || lowerMessage.includes('3d')) {
                    return "‰Ωú‰∏∫Êú¨Âú∞ÈÉ®ÁΩ≤ÁöÑÊ®°ÂûãÔºåÊàë‰∏∫ÊÇ®Êèê‰æõÔºö\n\n‚Ä¢ **ÈöêÁßÅ‰øùÊä§** - ÊÇ®ÁöÑÊï∞ÊçÆÂÆåÂÖ®Êú¨Âú∞Â§ÑÁêÜ\n‚Ä¢ **Á¶ªÁ∫øÂ∑•‰Ωú** - Êó†ÈúÄÁΩëÁªúËøûÊé•Âç≥ÂèØ‰ΩøÁî®\n‚Ä¢ **ÂÆöÂà∂Âåñ** - ÈíàÂØπ Houdini Â∑•‰ΩúÊµÅÁ®ã‰ºòÂåñ\n‚Ä¢ **Âø´ÈÄüÂìçÂ∫î** - Êú¨Âú∞Êé®ÁêÜÔºåÂª∂ËøüÊõ¥‰Ωé\n\nÊÇ®ÁöÑÊï∞ÊçÆÂÆâÂÖ®ÊòØÊàë‰ª¨ÁöÑÈ¶ñË¶ÅËÄÉËôë„ÄÇËØ∑ÊîæÂøÉÂàÜ‰∫´ÊÇ®ÁöÑÈ°πÁõÆÈúÄÊ±ÇÔºÅ";
                }
                return `[Êú¨Âú∞Ê®°Âûã] Â∑≤Êî∂Âà∞Ôºö"${message}"\n\n‰Ωú‰∏∫Êú¨Âú∞ÈÉ®ÁΩ≤ÁöÑ AI Ê®°ÂûãÔºåÊàëÁ°Æ‰øùÊÇ®ÁöÑÊï∞ÊçÆÈöêÁßÅÂíåÂÆâÂÖ®„ÄÇËØ∑ÂëäËØâÊàëÊÇ®ÁöÑ Houdini È°πÁõÆÈúÄÊ±ÇÔºåÊàë‰ºöÂú®Êú¨Âú∞‰∏∫ÊÇ®Êèê‰æõÂ∏ÆÂä©„ÄÇ`;
            }
            
            async testHoudiniConnection() {
                try {
                    // Test if we can access the Houdini bridge
                    if (window.hostBridge) {
                        this.updateStatus('connected');
                        console.log('‚úÖ Connected to Houdini bridge');
                        
                        // Test the bridge
                        try {
                            const selection = await window.hostBridge.houdiniSelection();
                            if (selection) {
                                console.log('Houdini selection:', selection);
                            }
                        } catch (error) {
                            console.log('Houdini bridge test:', error);
                        }
                    } else {
                        this.updateStatus('disconnected');
                        console.log('‚ö†Ô∏è Houdini bridge not available');
                    }
                } catch (error) {
                    this.updateStatus('error');
                    console.error('Connection test failed:', error);
                }
            }
            
            updateStatus(status) {
                this.statusIndicator.className = `status-indicator ${status}`;
            }
        }
        
        // Initialize the chat when the page loads
        window.addEventListener('load', () => {
            new CherryStudioChat();
        });
    </script>
</body>
</html>
